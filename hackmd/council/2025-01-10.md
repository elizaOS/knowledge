# Council Briefing: 2025-01-10

## Monthly Goal

December 2025: Execution excellence—complete token migration with high success rate, launch ElizaOS Cloud, stabilize flagship agents, and build developer trust through reliability and clear documentation.

## Daily Focus

- Stability work surfaced as the dominant strategic lever: new plugins and integrations shipped, but the Council’s critical path is to harden core client behavior (Twitter/Telegram/DB) and convert that reliability into developer trust via clear docs and predictable releases.

## Key Points for Deliberation

### 1. Topic: Reliability of Social Clients (Twitter/Telegram) as Trust Infrastructure

**Summary of Topic:** Operational signals show repeated friction in Twitter authentication/rate-limits and Telegram double-response behavior; shipping fixes (e.g., reusing Twitter sessions) must be paired with release hygiene (npm publishing, configuration clarity) to protect developer trust.

#### Deliberation Items (Questions):

**Question 1:** Do we treat Twitter/Telegram reliability as a “Tier-0” stability program (with dedicated maintainers, release cadence, and test gates), even if it slows new plugin intake?

  **Context:**
  - `GitHub Daily Update (2025-01-10): "Fixed repeated login issues by reusing the client-twitter session" (PR #2129).`
  - `GitHub Issues (2025-01-09 daily summary): "Users experiencing double responses when interacting on Telegram" (Issue #2089).`

  **Multiple Choice Answers:**
    a) Yes—declare social clients Tier-0 with explicit SLAs, test coverage targets, and a release train.
        *Implication:* Improves trust and retention for real deployments, but reduces bandwidth for rapid ecosystem expansion.
    b) Partially—Tier-0 only for Twitter; Telegram remains community-supported until usage justifies escalation.
        *Implication:* Focuses resources where visible impact is highest, but risks fragmentation and uneven multi-platform UX.
    c) No—keep feature velocity; accept client instability as early-stage cost and rely on community fixes.
        *Implication:* Maximizes breadth short-term, but increases churn and damages the “reliable framework” North Star.
    d) Other / More discussion needed / None of the above.

**Question 2:** What is the Council’s preferred policy for “last-mile” integration failures that block adoption (e.g., plugin not published to npm, misconfig defaults): strict release gates or fast patches?

  **Context:**
  - `GitHub Issues (2025-01-09 daily summary): "The Twitter plugin (@elizaos/plugin-twitter) has not been published to npm" (Issue #2114).`
  - `Discord (2025-01-09 coders): recurring setup/config questions (POST_INTERVAL_MIN/MAX, parsing.ts footer issues).`

  **Multiple Choice Answers:**
    a) Strict gates: no merge without publish plan, versioning, and a documented config path.
        *Implication:* Reduces downstream chaos and support load, but increases maintainer overhead and PR cycle time.
    b) Hybrid: merge quickly behind flags, but require publish + docs within a fixed timebox (e.g., 72 hours).
        *Implication:* Balances velocity with accountability; requires enforcement mechanisms and ownership clarity.
    c) Fast patches: prioritize merges and rely on post-merge hotfixing and community documentation.
        *Implication:* Shortens time-to-merge, but creates recurring trust debt and “it works on main” instability.
    d) Other / More discussion needed / None of the above.

**Question 3:** How should we standardize agent posting behavior to reduce platform bans (rate limiting, shadow bans) while preserving autonomy?

  **Context:**
  - `Discord (2025-01-08): "How long does a Twitter shadow ban last?" (chainvirus: "3-7 days").`
  - `Discord (2025-01-09 coders): environment controls discussed (POST_INTERVAL_MIN, POST_INTERVAL_MAX, POST_IMMEDIATELY).`

  **Multiple Choice Answers:**
    a) Default to conservative safety: low frequency, randomized intervals, strong deduplication, and safe-mode templates.
        *Implication:* Protects accounts and reputation, but may reduce perceived agent “liveness” for growth loops.
    b) Provide selectable profiles (Conservative / Standard / Aggressive) with clear risk labeling.
        *Implication:* Improves DX and transparency; shifts accountability to builders while keeping sane defaults.
    c) Leave it fully configurable with minimal defaults; document best practices only.
        *Implication:* Maximizes flexibility, but keeps support burden high and increases platform enforcement incidents.
    d) Other / More discussion needed / None of the above.

---


### 2. Topic: Plugin Expansion vs Execution Excellence (Portfolio Discipline)

**Summary of Topic:** A surge of new plugins and integrations (Akash, Lens, TEE/Verified Inference docs, embeddings, vision) demonstrates ecosystem momentum, yet the monthly directive prioritizes reliability—requiring stricter intake criteria, maintenance ownership, and de-risking of reversions.

#### Deliberation Items (Questions):

**Question 1:** What intake policy should govern new plugins so we remain “open & composable” without sacrificing stability and DX?

  **Context:**
  - `Daily Report (2025-01-09): multiple major plugins added (Akash PR #2111, Lens PR #2101, nineteen.ai PR #2022, Gemini vision PR #2099).`
  - `Daily Report (2025-01-09): feature "Proof of Pizza" added then reverted (PR #2042, #2075).`

  **Multiple Choice Answers:**
    a) Adopt a “graduation pipeline”: experimental → community → supported, with clear criteria (tests, docs, maintainer).
        *Implication:* Creates a scalable ecosystem model while protecting core reliability and expectations.
    b) Freeze new plugins until core client stability targets are met; only accept bugfixes and docs.
        *Implication:* Maximizes execution excellence short-term, but risks community disengagement and missed integrations.
    c) Keep accepting broadly, but enforce automated lint/test checks and allow fast reverts for unstable additions.
        *Implication:* Sustains velocity, but may normalize churn and erode the perception of a stable framework.
    d) Other / More discussion needed / None of the above.

**Question 2:** How aggressively should we pursue “verifiable agent” infrastructure (TEE logging, SGX, verified inference) as a differentiator relative to Cloud and framework reliability?

  **Context:**
  - `Daily Report (2025-01-09): "TEE logging and Intel SGX support" (PR #1470).`
  - `Daily Update (2025-01-10): "Implemented Verified Inference documentation" (PR #2125).`

  **Multiple Choice Answers:**
    a) Prioritize verifiability now as a flagship differentiator; invest in reference implementations and docs.
        *Implication:* Strengthens trust narratives and enterprise/DAO use cases, but competes with core stability resources.
    b) Maintain as parallel track: keep shipping incremental TEE work, but gate it behind opt-in flags and minimal core coupling.
        *Implication:* Preserves momentum without destabilizing the mainline developer experience.
    c) Defer verifiability until Cloud launch and flagship agent stability are complete.
        *Implication:* Reduces scope and risk, but may concede leadership in “trustable agents” to competitors.
    d) Other / More discussion needed / None of the above.

**Question 3:** Given cross-chain momentum (Arbitrum, Hyperlane discussions), what is the Council’s preferred sequencing: ship framework-level primitives first or showcase via flagship agent demos?

  **Context:**
  - `Discord (2025-01-08): "Arbitrum Support" announced expansion of cross-chain capabilities.`
  - `Discord tokenomics (2025-01-09): Hyperlane multi-chain deployment steps shared by wit.`

  **Multiple Choice Answers:**
    a) Framework primitives first (stable APIs, docs, test suites), then flagship demos.
        *Implication:* Reduces technical debt and ensures composability, but delays visible narrative wins.
    b) Flagship demos first to prove value (end-to-end cross-chain agent), then harden primitives from learnings.
        *Implication:* Accelerates mindshare and partner adoption, but risks brittle patterns becoming de facto standards.
    c) Run in tandem with a strict interface contract: demos can move fast, but must not bypass stable core APIs.
        *Implication:* Balances speed with architecture discipline; requires strong review and governance.
    d) Other / More discussion needed / None of the above.

---


### 3. Topic: Developer Trust: Documentation, Onboarding, and “Taming Information” Automation

**Summary of Topic:** Community support load remains high (setup gaps, missing scripts in starter repos, RAG/memory confusion), while the project is already building digest automation; consolidating “how to succeed” docs and automating triage/digests is a direct trust multiplier.

#### Deliberation Items (Questions):

**Question 1:** Should we prioritize a single “Golden Path” onboarding (quickstart + production deploy + common pitfalls) over incremental docs patches across many plugins?

  **Context:**
  - `Discord (2025-01-09): "Several users reported issues with the eliza-starter repository missing scripts compared to the main repo".`
  - `Discord (2025-01-09 Action Items): "Create comprehensive guide for new developers" (Point Rat).`

  **Multiple Choice Answers:**
    a) Yes—ship a Golden Path first, and treat everything else as secondary until support volume drops.
        *Implication:* Cuts friction fastest and improves retention, but may leave long-tail plugins under-documented temporarily.
    b) Split: Golden Path for core + top 5 clients/plugins, while community maintains the long tail via templates and automation.
        *Implication:* Builds a scalable documentation model aligned with open-source realities.
    c) No—continue broad documentation improvements across the ecosystem as PRs arrive.
        *Implication:* Improves breadth, but risks never solving the top onboarding pain that blocks adoption.
    d) Other / More discussion needed / None of the above.

**Question 2:** What is the Council’s preferred mechanism to operationalize “Taming Information” (Discord/GitHub/X) into authoritative guidance: agent-run daily digests, curated human editorial, or hybrid?

  **Context:**
  - `Discord partners (2025-01-09 Action Items): "Create an automated Twitter bot to post daily updates from GitHub" (jin).`
  - `Discord (2025-01-08 Action Items): "Create an automated daily digest from X, Discord, and GitHub" (jin).`

  **Multiple Choice Answers:**
    a) Agent-first: fully automated daily digests and auto-generated GitHub issues, with minimal human review.
        *Implication:* Scales rapidly, but increases risk of misinformation and mis-prioritized work.
    b) Hybrid: agents draft digests/issues; humans approve and label; publish a canonical weekly council brief.
        *Implication:* Balances scale with accuracy; requires small but consistent editorial capacity.
    c) Human-curated: rely on maintainers and moderators to summarize and publish; agents used only as assistants.
        *Implication:* Maximizes quality control, but does not scale with community growth and high-volume contributions.
    d) Other / More discussion needed / None of the above.

**Question 3:** How should we formalize “known issues” around memory/RAG/DB to prevent repeated support loops (e.g., SQLite vector errors, Postgres failures with large knowledge)?

  **Context:**
  - `Daily Update (2025-01-10): "Reported sporadic PostgresDB connection failures when handling large knowledge sections" (Issue #2085).`
  - `Discord (2025-01-07): "zero-length vectors not supported" SQLite error often resolved by deleting DB and restarting (MonteCrypto).`

  **Multiple Choice Answers:**
    a) Create a canonical Troubleshooting Index with symptom → cause → fix, linked from CLI output and docs home.
        *Implication:* Reduces repeated support queries and increases perceived reliability immediately.
    b) Bake self-healing into runtime (auto-detect corrupted vectors, migrations, safer defaults) and keep docs minimal.
        *Implication:* Best long-term UX, but requires engineering time and careful regression testing.
    c) Leave troubleshooting to Discord/community and GitHub issues; focus on new features and plugins.
        *Implication:* Preserves velocity, but compounds trust debt and increases maintainer burnout.
    d) Other / More discussion needed / None of the above.