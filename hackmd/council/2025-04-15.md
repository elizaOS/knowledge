# Council Briefing: 2025-04-15

## Monthly Goal

December 2025: Execution excellence—complete token migration with high success rate, launch ElizaOS Cloud, stabilize flagship agents, and build developer trust through reliability and clear documentation.

## Daily Focus

- The fleet advanced core UX and social integrations (notably Twitter + UI control improvements), but Council attention is pulled toward imminent partner-aligned launches (Auto.fun + V2) amid unresolved plugin-compatibility and documentation gaps that threaten developer trust.

## Key Points for Deliberation

### 1. Topic: V2 Launch Readiness vs Plugin Ecosystem Continuity

**Summary of Topic:** V2 is described as launching "this week" with a partner, yet v1 plugins are explicitly not compatible with v2, driving user confusion and blocking real deployments; multi-agent defaults (“the-org”) are a bright spot but education is thin.

#### Deliberation Items (Questions):

**Question 1:** Do we gate the V2 launch behind a minimal “plugin continuity pack” (OpenAI + Twitter/Discord + Postgres/knowledge) to protect developer trust, even if it delays the ceremony?

  **Context:**
  - `Dev Discord 2025-04-14 (Odilitime): "V1 plugins don't work with v2 yet."`
  - `Dev Discord 2025-04-14 (shaw): launch is "this week" with a partner; education is "thin".`

  **Multiple Choice Answers:**
    a) Yes—delay until a core plugin continuity pack is stable and documented.
        *Implication:* Protects Execution Excellence and reduces churn, but risks partner/market momentum and narrative control.
    b) No—launch on schedule, but label V2 as “beta production” and publish a strict compatibility matrix + migration path.
        *Implication:* Preserves timeline while lowering expectation; trust depends on clarity and rapid follow-up patches.
    c) Hybrid—launch V2 core, but officially recommend v0.25.9/v1 for production until plugins complete migration.
        *Implication:* Maintains forward progress without breaking builders; requires strong messaging to avoid ecosystem fragmentation.
    d) Other / More discussion needed / None of the above.

**Question 2:** What becomes the canonical developer on-ramp during the transition: v2-develop branch, v1 stable, or a curated “golden path” installer?

  **Context:**
  - `Dev Discord 2025-04-14 (0xbayo): "github -> checkout v2-develop"`
  - `Discord 2025-04-14: "Manual cloning is preferred... includes the web client and all code for reference" (chris.troutner, yung_algorithm).`

  **Multiple Choice Answers:**
    a) Make a curated “golden path” installer the only recommended on-ramp (tested, pinned versions, includes web UI).
        *Implication:* Maximizes DX consistency; higher maintenance burden but aligns with reliability-first strategy.
    b) Keep v1 stable as the recommended path; position v2-develop as an opt-in builder preview.
        *Implication:* Reduces support load and preserves trust, but slows adoption of v2 primitives (tasks/multi-agent).
    c) Promote v2-develop as the default, accepting breakage as the price of rapid iteration.
        *Implication:* Accelerates v2 ecosystem formation but risks reputation damage if newcomers hit failures immediately.
    d) Other / More discussion needed / None of the above.

**Question 3:** How do we operationalize “multi-agent by default” (the-org) into a trust-building flagship demo rather than a confusing novelty?

  **Context:**
  - `Dev Discord 2025-04-14 (shaw): "By default that's how it runs... 'the org' is in the v2 repo now."`

  **Multiple Choice Answers:**
    a) Ship the-org as a scripted, one-command demo with preconfigured models, tasks, and observability.
        *Implication:* Turns a capability into a repeatable proof of reliability; sets a benchmark for ecosystem integrations.
    b) Keep the-org as a developer example only; prioritize single-agent stability and plugin migration first.
        *Implication:* Reduces scope risk but delays showcasing composability—the differentiator of the framework.
    c) Convert the-org into a hosted Cloud template (even if limited) to demonstrate end-to-end deployment.
        *Implication:* Directly supports the Cloud narrative; raises operational risk if infrastructure isn’t fully hardened.
    d) Other / More discussion needed / None of the above.

---


### 2. Topic: Reliability & DX: High-Frequency Failures in Core Workflows

**Summary of Topic:** User-facing failures cluster around agent creation, plugin installation (OpenAI), Twitter mention detection, PGlite on Mac, and Postgres embedding edge-cases (Levenshtein 255 limit). GitHub shows strong shipping velocity, but the pain is concentrated in “first hour” onboarding and debugging surfaces (logging/env behavior).

#### Deliberation Items (Questions):

**Question 1:** Which “first-hour” reliability issues must be declared Priority Zero before any further feature expansion?

  **Context:**
  - `Discord 2025-04-14: agent creation errors, OpenAI plugin installation issues, Twitter mentions not detected, PGlite on Mac.`
  - `Issue #4282: "V2 - `LOG_LEVEL=` env not responding" (Titan-Node).`

  **Multiple Choice Answers:**
    a) Onboarding blockers first: agent creation + OpenAI plugin install + CLI correctness across OSes.
        *Implication:* Improves activation rates and reduces support load; delays advanced features but aligns with Developer First.
    b) Social reliability first: Twitter mention detection + posting controls + long-tweet support stabilization.
        *Implication:* Protects flagship agents and public perception; may not fix core framework adoption friction.
    c) Data integrity first: PGlite/Postgres + embeddings/knowledge stability + logging/observability.
        *Implication:* Strengthens persistence and RAG trust; might leave newcomers stuck earlier in the funnel.
    d) Other / More discussion needed / None of the above.

**Question 2:** Do we impose a cross-platform CI gate (Mac/Windows/Linux) for CLI and plugin install flows before merging high-impact PRs?

  **Context:**
  - `Dev Discord 2025-04-12: CLI commands tested "only on Mac chip" (yung_algorithm); requests for CI across Mac/PC/Linux (jin).`

  **Multiple Choice Answers:**
    a) Yes—mandatory CI gating for CLI + install + minimal smoke tests, even if merge velocity slows.
        *Implication:* Reduces regressions and reinforces “trust through shipping,” at the cost of short-term throughput.
    b) Partial—gate only release branches; allow main to move fast with periodic stabilization sprints.
        *Implication:* Balances speed and stability but risks repeated onboarding breakages for builders tracking main.
    c) No—keep velocity; rely on community to surface issues rapidly and patch forward.
        *Implication:* Maximizes feature throughput but entrenches the perception of fragility and increases support burden.
    d) Other / More discussion needed / None of the above.

**Question 3:** How should we handle “edge-case hard errors” in knowledge/embeddings (e.g., Levenshtein length) to avoid silent failure or cryptic stack traces?

  **Context:**
  - `Coders 2025-04-14: Postgres plugin hits "levenshtein argument exceeds maximum length of 255 characters"; fix proposed via PR (.0xbbjoker).`

  **Multiple Choice Answers:**
    a) Fail fast with actionable remediation: detect input lengths and return a clear error with links to docs.
        *Implication:* Improves DX and support efficiency; requires disciplined error taxonomy and documentation.
    b) Auto-degrade: switch to a safer similarity method when inputs exceed limits, with warnings.
        *Implication:* Keeps systems running, but may mask quality drops and complicate reproducibility.
    c) Offload to a standardized vector store interface and deprecate bespoke similarity paths in core plugins.
        *Implication:* Long-term architectural cleanliness; near-term migration pain and potential community plugin breakage.
    d) Other / More discussion needed / None of the above.

---


### 3. Topic: Auto.fun Launch: Token Flywheel, Trust, and Security Posture

**Summary of Topic:** Auto.fun is poised to launch imminently, positioned as an “Ultra-Fun, Anti-Pump” launchpad with a SOL→AI16z buyback flywheel, but community sentiment signals information opacity and security anxiety; an Immunefi partnership is proposed to formalize bug bounties and audits.

#### Deliberation Items (Questions):

**Question 1:** What minimum “truth package” must be published before Auto.fun ignition to prevent trust erosion (mechanics, risks, revenue paths, roles)?

  **Context:**
  - `Discord 2025-04-14: requests for "detailed information" and frustration about lack of clear communication.`
  - `Partners 2025-04-14 (Borko): Notion doc shared; "updated tokenomics... will be shared as well."`

  **Multiple Choice Answers:**
    a) Publish full mechanics + explicit risk disclosures + FAQs + diagrams + timeline, even if it reveals trade secrets.
        *Implication:* Maximizes credibility and reduces rumor load; may expose competitive details but supports long-term trust.
    b) Publish a constrained spec: user flow + token flow diagram + security posture + post-launch transparency schedule.
        *Implication:* Balances secrecy and trust; success depends on honoring the promised transparency cadence.
    c) Keep details minimal until launch to reduce attack surface and narrative manipulation.
        *Implication:* May protect short-term ops, but increases speculation, support burden, and reputational volatility.
    d) Other / More discussion needed / None of the above.

**Question 2:** Should we initiate an Immunefi program immediately for Auto.fun/ElizaOS, or first complete internal hardening and scoped audits?

  **Context:**
  - `Partners 2025-04-14 (yikesawjeez): proposal for Immunefi partnership for security audits and bug bounties; concerns about TypeScript + third-party vendors.`

  **Multiple Choice Answers:**
    a) Launch Immunefi now with a narrow scope (critical contracts/transaction paths) and staged rewards.
        *Implication:* Signals seriousness and can catch issues early; requires rapid triage capacity and clear rules of engagement.
    b) Do internal hardening + a targeted third-party audit first, then open Immunefi after initial fixes.
        *Implication:* Reduces noise and false positives; delays public assurance and may miss early external discoveries.
    c) Defer formal programs; rely on open-source review until the architecture stabilizes (potentially moving runtimes later).
        *Implication:* Saves cost/ops overhead but increases the risk of a credibility-damaging incident during launch window.
    d) Other / More discussion needed / None of the above.

**Question 3:** How tightly should Auto.fun’s token flywheel be coupled to ElizaOS’s developer narrative without conflating product lines?

  **Context:**
  - `Discord 2025-04-14 (anon): "sol used on autofun will go back to buy ai16z. completing the flywheel"; repeated questions on holder profit mechanisms.`

  **Multiple Choice Answers:**
    a) Strong coupling: present Auto.fun as the flagship economic engine funding/validating ElizaOS agents.
        *Implication:* Amplifies growth narrative but heightens reputational risk if Auto.fun experiences turbulence.
    b) Moderate coupling: share token flow transparently, but keep ElizaOS positioned as neutral infrastructure.
        *Implication:* Preserves developer-first neutrality while still benefiting from ecosystem economics.
    c) Loose coupling: minimize cross-branding; treat Auto.fun as a separate experiment with limited promises.
        *Implication:* Reduces systemic brand risk, but may weaken the ecosystem’s perceived coherence and utility story.
    d) Other / More discussion needed / None of the above.