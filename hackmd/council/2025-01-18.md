# Council Briefing: 2025-01-18

## Monthly Goal

December 2025: Execution excellence—complete token migration with high success rate, launch ElizaOS Cloud, stabilize flagship agents, and build developer trust through reliability and clear documentation.

## Daily Focus

- A reliability-centric push accelerated today: expanded automated test coverage and hardened key clients/plugins (notably Telegram) while new issues continue to surface around real-world deployment friction and brittle third-party integrations.

## Key Points for Deliberation

### 1. Topic: Execution Excellence: Test Coverage and Release Hardening

**Summary of Topic:** Engineering throughput remains high (dozens of PRs daily), with a visible shift toward stability work: tests added for Redis and DB adapters and more structured CI/config checks. The Council should decide how aggressively to prioritize a “quality gate” posture to convert velocity into dependable releases (and Cloud trust).

#### Deliberation Items (Questions):

**Question 1:** Do we impose stricter merge gates (tests + platform smoke tests) even if it reduces merge velocity in the short term?

  **Context:**
  - `GitHub activity: "45 new pull requests with 37 merged" and "16 new issues" (Jan 17-18).`
  - `Daily report: "Added tests for Supabase and SQLite DB adapters (PR #2468)" and "Added tests for Redis adapter (PR #2470)".`

  **Multiple Choice Answers:**
    a) Yes—raise gates immediately (tests required for core paths and tier-1 plugins).
        *Implication:* Short-term slowdown buys long-term developer trust, fewer regressions, and safer Cloud defaults.
    b) Partial—apply strict gates only to core runtime, adapters, and flagship clients; keep looser gates for community plugins.
        *Implication:* Protects reliability where it matters most while preserving ecosystem experimentation velocity.
    c) No—maintain velocity and rely on rapid patching + community feedback loops.
        *Implication:* Growth remains fast, but operational instability risks eroding credibility precisely as Cloud/flagships need trust.
    d) Other / More discussion needed / None of the above.

**Question 2:** Where should the next reliability investment concentrate: adapters/storage, client integrations, or CI/tooling standardization?

  **Context:**
  - `New issue: "database/index.ts file not utilizing the CACHE_STORE environment variable (Issue #2511)".`
  - `Daily report: "Introduced test configurations and coverage for the Binance plugin (PR #2482)".`

  **Multiple Choice Answers:**
    a) Adapters/storage first (DB correctness, migrations, cache semantics).
        *Implication:* Stabilizes the persistence layer underpinning Cloud and long-running agents, reducing hard-to-debug failures.
    b) Client integrations first (Twitter/Telegram/Discord reliability).
        *Implication:* Improves user-perceived stability and reduces support load from high-visibility failures.
    c) CI/tooling first (linting, reproducible builds, smoke tests, release automation).
        *Implication:* Reduces regressions systematically and makes large contributor volume sustainable.
    d) Other / More discussion needed / None of the above.

**Question 3:** Should we formalize a “blessed baseline” (known-good stack) for developers (DB + embeddings + clients), even if it reduces optionality?

  **Context:**
  - `Discord coders: "dimension mismatches when trying to use different embedding models" and debates over SQLite vs PostgreSQL/Supabase.`
  - `Daily report: tests added for Redis/SQLite/Supabase adapters (PR #2470, #2468).`

  **Multiple Choice Answers:**
    a) Yes—publish an official baseline (e.g., SQLite/PGlite + OpenAI embeddings + pinned client versions).
        *Implication:* Fewer support incidents and faster onboarding, at the cost of reduced experimentation.
    b) Two baselines—Local (SQLite/PGlite) and Cloud (Postgres/Supabase), each documented and tested.
        *Implication:* Balances DX and production readiness, but increases documentation and CI matrix complexity.
    c) No—keep everything modular and let builders choose; invest only in better docs.
        *Implication:* Maximal composability, but ongoing fragmentation increases developer friction and inconsistent outcomes.
    d) Other / More discussion needed / None of the above.

---


### 2. Topic: Integration Volatility: Twitter Friction vs Telegram Momentum

**Summary of Topic:** Telegram gained multimedia capability, but Twitter remains a frequent failure point (Arkose login, rate limits, reply correctness). The Council should decide whether to treat Twitter as a “best-effort” integration, or to fund a hardened, compliance-aware subsystem to protect reliability and brand trust.

#### Deliberation Items (Questions):

**Question 1:** Do we pursue a hardened Twitter integration (robust auth + rate-limit strategy + reply correctness), or downgrade Twitter support to “experimental/best-effort” until Cloud stabilizes?

  **Context:**
  - `Discord coders: "Login attempt failed: Unknown subtask ArkoseLogin" (validsyntax advised VPN workaround).`
  - `Action item: "Fix Twitter client to handle rate limits better for replies" (Moxtin).`

  **Multiple Choice Answers:**
    a) Harden now—dedicate an owner, implement resilient auth + backoff + observability, and publish a support matrix.
        *Implication:* Reduces high-visibility failures and support burden, but requires ongoing maintenance against shifting platform defenses.
    b) Mark Twitter as experimental—focus stability on Discord/Telegram while maintaining minimal fixes for Twitter.
        *Implication:* Protects overall reliability targets, but sacrifices a major distribution channel and may frustrate builders.
    c) Abstract social clients behind a unified reliability layer (queues, rate-limiters, retries) and let each client inherit it.
        *Implication:* Long-term scalable approach, but slower to deliver immediate relief for current Twitter pain.
    d) Other / More discussion needed / None of the above.

**Question 2:** What is the Council’s preferred posture toward third-party platform risk (e.g., Twitter anti-bot measures): workaround-driven or compliance-first?

  **Context:**
  - `Discord coders: workaround guidance included "using VPNs" and "setting automated account flags" to resolve Twitter auth/rate issues.`
  - `GitHub issue list includes multiple Twitter bot behavior bugs (e.g., "Unexpected JSON metadata appearing in Twitter bot replies").`

  **Multiple Choice Answers:**
    a) Compliance-first: avoid workaround patterns that resemble evasion; prioritize approved APIs where possible.
        *Implication:* Lower ban risk and reputational risk, but may reduce capability and increase cost/latency.
    b) Pragmatic hybrid: document safe workarounds with clear risk warnings; build a path to compliant modes over time.
        *Implication:* Keeps builders shipping while creating an upgrade path; still carries moderate platform enforcement risk.
    c) Workaround-driven: optimize for results and let users manage account risk.
        *Implication:* Maximizes immediate utility but can damage trust and create cascading support crises when accounts are restricted.
    d) Other / More discussion needed / None of the above.

**Question 3:** Which client should be treated as “tier-1” for flagship reliability over the next sprint cycle?

  **Context:**
  - `Daily update: "Added extra multimedia support for the Telegram client (PR #2510)."`
  - `Discord: multiple users report Twitter authentication and rate limiting problems across days.`

  **Multiple Choice Answers:**
    a) Discord + Telegram as tier-1; Twitter tier-2.
        *Implication:* Maximizes stability on channels with fewer hostile constraints and strong community presence.
    b) Twitter remains tier-1 due to growth/distribution; invest accordingly.
        *Implication:* Potentially highest upside, but reliability may remain fragile due to platform volatility.
    c) Tier-1 is “Cloud-native web UI + API”; all social clients are tier-2.
        *Implication:* Centers the product around Cloud and developer workflows, reducing dependence on external platforms.
    d) Other / More discussion needed / None of the above.

---


### 3. Topic: Trust Through Clarity: Documentation, Roadmaps, and Tokenomics Narrative Control

**Summary of Topic:** Community energy is strong but repeatedly requests clearer roadmaps (tokenomics phases, DegenAI direction, hosting/how-to guides, RAG setup). Operationally, documentation and automated communications (daily updates/leaderboards) are emerging as the control surface to prevent fragmented narratives and preserve developer trust.

#### Deliberation Items (Questions):

**Question 1:** Do we publish a single canonical roadmap (tokenomics + Cloud + flagship stability) even if it must be revised frequently, or keep plans modular and informal until execution is locked?

  **Context:**
  - `Discord partners/tokenomics: requests for "a simple roadmap" and "comprehensive tokenomics roadmap with clear phases and timelines" (rhota, Ka_yari).`
  - `Jin outlined phases: "DAO tribute phase 2, autonomous memecoin traders, AI investing in ecosystem projects, agent marketplace, retro funding for devs".`

  **Multiple Choice Answers:**
    a) Publish a canonical roadmap with explicit confidence levels (Committed / Planned / Exploratory).
        *Implication:* Improves trust and alignment while acknowledging uncertainty in a fast-moving system.
    b) Publish only near-term milestones (2–4 weeks) and keep long-term narrative as principles.
        *Implication:* Reduces rework and broken promises, but may not satisfy stakeholders seeking longer-horizon clarity.
    c) Keep roadmap informal; let shipping speak and avoid forward-looking commitments.
        *Implication:* Minimizes narrative risk, but leaves a vacuum that rumors and confusion will fill.
    d) Other / More discussion needed / None of the above.

**Question 2:** How should we operationalize “Taming Information” to reduce repeated support questions (Twitter auth, RAG setup, multi-agent secrets)?

  **Context:**
  - `Discord coders: repeated questions on "how to properly implement knowledge files" and "how to activate plugins" and "run multiple agents".`
  - `Action item: "Automate daily updates and weekly threads of completed work" (jin) and "Eliza leaderboard" development.`

  **Multiple Choice Answers:**
    a) Build an official Council-run “Answer Engine” agent fed by docs + GitHub + Discord summaries, with citations.
        *Implication:* Reduces support load and scales onboarding; becomes a flagship demonstration of ElizaOS itself.
    b) Focus on curated docs: 10–15 “golden guides” + troubleshooting playbooks, updated weekly.
        *Implication:* High leverage and low risk; slower to respond to novel issues but more reliable for developers.
    c) Rely on community helpers and ad-hoc Discord support; optimize channel organization by experience level.
        *Implication:* Fast and social, but inconsistent and harder to convert into lasting institutional knowledge.
    d) Other / More discussion needed / None of the above.

**Question 3:** What is the Council’s desired relationship between “agent-led DAO automation” and human governance during the next phase of scaling?

  **Context:**
  - `Partners channel: "automation at the center, humans at the edges" (Shaw) and "automating functions of the DAO" (jin).`
  - `Associates channel: work toward automated updates and operational agents acting like "interns".`

  **Multiple Choice Answers:**
    a) Human-led with agent assistance: agents propose, humans approve and execute.
        *Implication:* Safest governance posture; slower, but reduces catastrophic automation errors.
    b) Agent-led in bounded domains (comms, reporting, low-risk ops), human-led for treasury and protocol decisions.
        *Implication:* Balances speed and safety while generating credible proof of autonomous operations.
    c) Agent-led by default with human veto; rapidly expand autonomy to treasury actions.
        *Implication:* Maximizes the “decentralized AI economy” thesis quickly, but carries severe downside if controls fail.
    d) Other / More discussion needed / None of the above.