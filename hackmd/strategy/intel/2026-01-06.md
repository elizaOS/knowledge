# ElizaOS Intel — 2026-01-06

## 1) Data Pattern Recognition

### Data completeness & confidence
- **Missing daily source files** for **2026-01-05** and **2026-01-06** → today’s intel is derived from:
  - Discord digests: **2026-01-03**, **2026-01-04**
  - GitHub rollups: weekly **(Dec 28–Jan 3)** and monthly **(Jan 1–Feb 1 window to date)**
- **Confidence: Medium** (strong signal on roadmap/engineering direction; weak signal on “today-only” incidents).

### Development velocity & trend
- **GitHub (month-to-date window: 2026-01-01 → 2026-02-01, current snapshot)**
  - **New PRs:** 2
  - **Merged PRs:** 2 (100% merge rate so far)
  - **New issues:** 20
  - **Closed issues:** 0
  - **Active contributors:** 6
  - **Code changes (snapshot):** +160 / -36 across 5 files; 17 commits (note: separate contributor logs indicate additional un-PR’d commit activity by some contributors)
- **Trend interpretation**
  - **High “planning/definition” load**: issues greatly outpace PRs (20 issues vs 2 PRs) → roadmap/specification phase for public agent ecosystem + UX polish.
  - **Execution focus** visible in one major performance refactor merged (**MultiStep provider parallelization**) and one critical DB isolation bugfix PR opened (**plugin-sql**).

### Community engagement patterns (Discord-derived)
- **High-intensity technical threads** cluster around:
  1) **Solana trading latency requirements** (GRPC ingestion, payload “preshot”, reaction-time constraints)
  2) **Build tooling pain**: Turbo builds reportedly consuming **21GB+ RAM**
  3) **Platform positioning/onboarding**: repeated “What is ElizaOS / why not just an LLM wrapper?” questions
  4) **Access gating**: Hyperscape dev Discord is “DM for access” (friction point)

### Feature adoption & demand signals (proxy)
- Strong demand/interest signals for:
  - **Multi-model agents** (Anthropic + OpenAI in one agent; routing tasks by provider)
  - **Containerized deployment via CLI** for custom plugins
  - **Public agent UX** improvements (issues opened in core repo: public agent states, guest limits, chat summaries, agent sorting)

### Pain point correlation across channels
- **UX friction + onboarding confusion**
  - Discord: “How does Eliza work?” repeated
  - GitHub: many UX issues opened (public agent states, guest gating, chat summaries)
- **Developer experience instability**
  - Discord: Turbo memory spike
  - GitHub: logging format linter added; plugin versioning complaints (Discord plugin publish gap); SQL isolation bugfix needed
- **Performance & reliability as critical enablers**
  - GitHub: provider parallelization merged (perf win)
  - Discord: Solana trading requires extreme low latency beyond typical agent loop → indicates a “capability boundary” that should be made explicit in docs/product messaging


## 2) User Experience Intelligence

### Feedback themes (categorized by impact)

**A) High impact (blocks adoption / causes failure)**
- **Build reliability / resource consumption**
  - Turbo builds reported at **21GB+ RAM** → can hard-block contributors and CI stability.
- **Plugin reliability & release hygiene**
  - Discord plugin versioning issue (v1.3.4 publish failure; jump to v1.3.5) → erodes trust, complicates debugging/support.
- **Data isolation DB bug (core correctness)**
  - SQL `SET LOCAL` parameterization bug breaks DB operations when isolation enabled (PR #6316 addresses).

**B) Medium impact (hurts conversion, retention)**
- **Public agent experience mismatch by user state**
  - Need separate UX for: unauthenticated visitor vs authenticated non-owner vs owner (GitHub issue #6313).
- **Chat summaries quality**
  - Summaries “don’t make sense” → undermines navigability and perceived product quality (issue #6311).
- **Onboarding/value proposition clarity**
  - Discord skepticism: “wrapper for AI models?” → indicates messaging gaps and missing “aha” examples.

**C) Opportunity (new capability pull)**
- **Multi-model routing patterns**
  - Users want explicit task→model selection; today it’s “possible” but not productized (Openrouter + env config).
- **Low-latency trading**
  - Community interest, but requirements imply it may be outside baseline ElizaOS promise unless specialized pipelines/plugins exist.

### Usage patterns vs intended design (observed)
- Users treat ElizaOS as:
  - A **plugin runtime + agent composition layer** (intended)
  - A potential **HFT-like execution environment** (likely not intended; requires boundary-setting)
- Users repeatedly ask “how does it work?” → indicates intended mental model is not landing; documentation/examples need to lead with concrete workflows.

### Implementation opportunities (UX + DevEx)
- **Productize “public agent states”** into a clear funnel:
  - Visitor: fast try (2–3 messages) → signup gate
  - Signed-in non-owner: chat + fork
  - Owner: manage + publish + analytics
- **Tighten developer onboarding**
  - One “golden path” guide: create agent → add plugin → deploy container → publish public link.
- **Introduce capability boundaries**
  - Explicitly document what ElizaOS is/isn’t for regarding millisecond-critical trading; recommend architecture patterns if pursuing it.

### Community sentiment (directional)
- **Positive**: active building (RoseOS framework shared), strong peer help, performance work landing.
- **Mixed**: doubts about differentiation, frustration around tooling/plugin publishing, and unclear access pathways (Hyperscape dev Discord).


## 3) Strategic Prioritization (Impact × Risk × Dependencies)

### Priority 0 (stability / unblocking)
1) **Turbo build memory investigation**
   - **User impact:** High (blocks contributors, potential CI cost blowups)
   - **Technical risk:** Medium (may involve monorepo config, caching, package graph)
   - **Recommendation:** Allocate **1–2 engineering days** to reproduce + cap memory usage; add CI telemetry for peak RAM.
   - **Deliverables:** repro steps, baseline vs fixed memory profile, documented mitigation (env flags / turborepo config).

2) **Plugin release/versioning hygiene (Discord plugin incident)**
   - **User impact:** High (breaks trust/supportability)
   - **Technical risk:** Low–Medium
   - **Recommendation:** Implement a **release checklist + automated publish verification** (tag→artifact→registry visibility), plus rollback guidance.
   - **Metric to track:** % releases with verified artifacts; time-to-detect publish failures.

### Priority 1 (conversion & core UX for public agents)
3) **Implement “separate public agent states” UX (issue #6313) + guest message limit (#6312)**
   - **User impact:** High (directly affects acquisition funnel from shared links)
   - **Technical risk:** Medium (auth state handling, routing, UI conditions)
   - **Critical dependencies:** Auth/session detection, consistent agent URL/state routing.
   - **Recommendation:** Treat as a **single epic** with acceptance tests:
     - Visitor sees minimal UI + 2–3 message limit + signup overlay
     - Signed-in non-owner sees Chat + Fork
     - Owner sees Edit/Manage + publish controls

4) **Fix “chat summaries don’t make sense” (issue #6311)**
   - **User impact:** Medium–High (daily usability; perceived quality)
   - **Technical risk:** Medium (summarization prompts, context selection, eval)
   - **Recommendation:** Add lightweight evaluation:
     - Human spot checks + simple heuristic metrics (length, redundancy, entity retention)
   - **Deliverables:** improved summarizer prompt/context strategy; rollback-safe flag.

### Priority 2 (performance, correctness, and positioning)
5) **Land SQL isolation fix (PR #6316)**
   - **User impact:** High for isolation-enabled deployments
   - **Technical risk:** Low (well-scoped; tests included)
   - **Recommendation:** Fast-track review/merge; announce in changelog since it’s “silent critical.”

6) **Docs: “What is ElizaOS?” + differentiated examples**
   - **User impact:** Medium (reduces repeated Discord questions; improves conversion)
   - **Technical risk:** Low
   - **Recommendation:** Publish 3 canonical examples:
     1) Multi-model routed agent
     2) Agent with knowledge pipeline + retrieval
     3) Agent with 3rd-party plugin (X/Discord) + container deploy
   - **Metric:** Reduction in repeated onboarding questions; doc completion rate.

### Capability boundary decision (avoid misaligned expectations)
7) **Solana low-latency trading guidance**
   - **User impact:** Medium (small segment, but high visibility)
   - **Technical risk:** High if pursued as core feature
   - **Recommendation:** Do **not** position baseline agents as suitable for millisecond trading. Instead:
     - Provide a reference architecture: external GRPC ingester + event queue + Eliza agent for strategy/decisioning at higher latency tiers.
     - If pursuing, scope as **separate “latency tier” plugin stack** with clear SLAs and required infra.

---

## Key Metrics to Start Tracking (next 2 weeks)
- **DevEx:** Turbo build peak RAM (local + CI), build time p50/p95
- **Reliability:** Plugin release success rate; publish failure detection time
- **Growth funnel:** Public agent link → first message → signup conversion; guest message exhaustion rate
- **UX quality:** Chat summary “helpfulness” quick rating (thumbs up/down) + fallback rate (manual rename/search)

## Actionable Recommendations (next sprint)
1) Assign an owner for **Turbo RAM** + produce a mitigation doc even if full fix takes longer.
2) Bundle **public agent states + guest gating** into one deliverable with clear UX acceptance criteria.
3) Merge **SQL isolation fix** with priority; communicate broadly.
4) Publish a **positioning + examples** doc to address “LLM wrapper” skepticism and reduce repetitive onboarding questions.
5) Add a minimal **release verification pipeline** for plugins to prevent version gaps and regain trust.