{
  "server": "Hyperfy",
  "title": "Hyperfy Discord - 2025-01-21",
  "date": 1737417600,
  "stats": {
    "totalMessages": 1479,
    "totalUsers": 84
  },
  "categories": [
    {
      "channelId": "994775534733115412",
      "channelName": "💻│developers",
      "summary": "# Analysis of 💻│developers Discord Chat\n\n## 1. Summary\nThe discussion primarily revolves around Hyperfy V2 development, focusing on technical implementation details and troubleshooting. Key topics include setting up Eliza AI agents in Hyperfy worlds, asset loading issues, infrastructure deployment options, and UI/scripting capabilities. \n\nDevelopers discussed nginx configuration for asset loading, with a solution involving increasing the `client_max_body_size` to 32M. The Eliza AI integration was a major focus, with detailed instructions shared for implementing AI avatars in Hyperfy worlds using the Eliza framework. This required specific server setup and code implementation.\n\nInfrastructure discussions covered AWS deployment strategies using ECS, EFS, and load balancers. UI development progress was shared, including the implementation of nametags using shaders with a single draw call and work on player chat bubbles. The scripting system in V2 was clarified as using vanilla JavaScript rather than React (which was used in V1), with a DOM-like API for creating and manipulating objects.\n\nSeveral developers successfully implemented AI agents in their worlds, with troubleshooting help provided for connection issues. The team is working on new environments, improved infrastructure, and enhanced UI capabilities.\n\n## 2. FAQ\nQ: Has anyone had issues with assets being unable to load after adding them and refreshing the page? (asked by m₂) A: It could be related to the .env max upload size (default 16MB) or nginx configuration limits (answered by Ashxn)\nQ: Has anyone else had troubles getting any hyperfy worlds to load on mac m1 in chrome? (asked by FrankyLimon) A: It was caused by having graphic acceleration turned off in Chrome (answered by FrankyLimon)\nQ: If I want to get started with v2 how do I go about it? (asked by FrankyLimon) A: Clone the repo, follow the quick start instructions in the README (answered by Saori)\nQ: Can you add characters to the Eliza server once it's already running? (asked by Lastraum) A: Currently not possible, characters can only be specified at startup (answered by hiroP)\nQ: Can we add an \"empty\" entity for scripting, or do they always need to be attached to a 3D representation? (asked by Lastraum) A: You can use app.create('group') but you need something visual to see where you're putting it (answered by Ashxn)\nQ: Can you currently rotate an item in world without scripting? (asked by MetaMike) A: Mouse wheel rotates on Y axis, hold shift and move mouse up/down to lift (answered by Ashxn)\nQ: Is Hyperfy V2 using WebGL or WebGPU as a foundation? (asked by TheMattEmpire) A: Currently WebGL but will move to WebGPU when it's ready (answered by Ashxn)\nQ: Is there a way to send an event from the server to a single client? (asked by peezy) A: Need to add world.emit and world.sendTo functions, on the to-do list (answered by Ashxn)\nQ: Is the scripting language just Three.js? (asked by FrankyLimon) A: It's a custom wrapper that's more like web DOM development (answered by Ashxn)\n\n## 3. Help Interactions\nHelper: Ashxn | Helpee: m₂ | Context: Assets not loading after refresh | Resolution: Added `client_max_body_size 32M;` to nginx server block\nHelper: Ashxn | Helpee: FrankyLimon | Context: Mac M1 Chrome loading issues | Resolution: Identified graphic acceleration was turned off in Chrome\nHelper: Saori | Helpee: FrankyLimon | Context: Getting started with V2 | Resolution: Provided step-by-step instructions for cloning and setting up\nHelper: Saori/Ashxn | Helpee: peezy | Context: Eliza app implementation | Resolution: Shared code and identified app.get('vrm') needed to be changed to app.get('avatar')\nHelper: peezy | Helpee: MetaMike | Context: Eliza server connection issues | Resolution: Identified URL format issue (extra slash) and need to rebuild after checkout\nHelper: Ashxn | Helpee: MetaMike | Context: Item rotation in world | Resolution: Explained mouse wheel rotates on Y axis, shift+mouse for vertical movement\n\n## 4. Action Items\nType: Technical | Description: Add world.emit and world.sendTo to target specific clients from server | Mentioned By: Ashxn\nType: Technical | Description: Implement runtime character addition to Eliza server | Mentioned By: Lastraum\nType: Technical | Description: Create new environments with better lighting | Mentioned By: MetaMike/Ashxn\nType: Technical | Description: Implement trimesh for collision detection | Mentioned By: Saori\nType: Technical | Description: Add toggleable nametags for recording videos | Mentioned By: hiroP\nType: Technical | Description: Consider using JSON files instead of SQLite for world data | Mentioned By: Ashxn\nType: Technical | Description: Implement clickable regions on UI nodes | Mentioned By: Ashxn\nType: Documentation | Description: Move Docker part of README to separate DOCKER.md | Mentioned By: Ashxn\nType: Documentation | Description: Document Eliza app implementation | Mentioned By: Saori\nType: Feature | Description: Add nuanced permissions system based on roles/zones | Mentioned By: maximus\nType: Feature | Description: Implement auto-scaling worlds based on user presence | Mentioned By: MetaMike",
      "messageCount": 357,
      "userCount": 19
    },
    {
      "channelId": "1330373197203505185",
      "channelName": "🤖│agents",
      "summary": "# Discord Chat Analysis for \"🤖│agents\" Channel\n\n## 1. Summary:\nThe channel discussions focus on AI agent development, specifically around character creation for conversational agents. Users shared information about deepseek-r1, a fast and cost-effective AI model. Saori shared a JSON template for creating character-based agents (using Donald Trump as an example), explaining that these templates define how AI agents behave, speak, and respond. The community discussed the need for more character.json files for avatars from VRoid Hub. Currently, implementing agents requires technical knowledge and an Eliza server, though there are plans to make this more accessible to non-technical users. MetaMike suggested forking Howie as a potential solution for multi-agent implementation. The conversation indicates the community is actively building a collection of character templates and exploring ways to deploy them as interactive agents.\n\n## 2. FAQ:\nQ: Are agents currently only available to people who know how to code? (asked by chiefdegen.eth) A: Yes, the main thing right now is you need an Eliza server (answered by Saori)\nQ: I want to be more involved in this, is there gonna be a user option later? (asked by chiefdegen.eth) A: Yes (answered by Saori)\nQ: Only if you own 25,000 $HYPER though, right? (asked by jar0d) A: No (answered by Saori)\nQ: You're saying I just copy this and I can make AI Agents? (asked by jar0d) A: That's how they work but we don't have a service to spin them up for users, looking into it (answered by Saori)\n\n## 3. Help Interactions:\nHelper: Saori | Helpee: jar0d | Context: Understanding how to create AI agents with JSON templates | Resolution: Explained that while the JSON defines the agent, they don't yet have a service to deploy them for users\nHelper: Saori | Helpee: chiefdegen.eth | Context: Wanting to get involved with agents without coding knowledge | Resolution: Confirmed that user-friendly options would be available in the future\nHelper: bitpixi | Helpee: Channel members | Context: Creating character JSONs efficiently | Resolution: Shared that they created 12 bot JSONs in about a minute, demonstrating the process is fast\n\n## 4. Action Items:\nTechnical: Create more character.json files for avatars available on VRoid Hub | Description: Expand the library of character templates for agent creation | Mentioned By: Saori\nTechnical: Implement a service to deploy agents for non-technical users | Description: Develop a way for users without coding knowledge to create and use agents | Mentioned By: Saori\nTechnical: Fork Howie for multiagent implementation | Description: Use Howie as a base for developing multiagent capabilities | Mentioned By: MetaMike\nFeature: Organize a \"Treasure hunt: Agents Vs Sybils\" event | Description: Create an interactive game or challenge involving agents | Mentioned By: ApeironCreations\nTechnical: Explore Pillzumi project for potential avatar integration | Description: Investigate using Pillzumi characters as agent avatars | Mentioned By: Malloy",
      "messageCount": 38,
      "userCount": 10
    },
    {
      "channelId": "958209074045026327",
      "channelName": "⚡│general",
      "summary": "# Analysis of Discord Chat in \"⚡│general\" Channel\n\n## 1. Summary\nThe chat primarily revolves around Hyperfy, a platform for creating 3D virtual worlds and experiences. Technical discussions focused on several key areas: avatar integration (VRM files and CloneX models), audio implementation for AI agents, and concert/event hosting capabilities. Users discussed the challenges of converting 3D models to VRM format and optimizing them for browser performance. There was significant interest in hosting virtual concerts, with specific discussion about audio streaming methods (m3u8 vs mp4) and synchronizing audio across instances. The community also discussed AI integration, with demonstrations of AI agents interacting in virtual spaces. Several members shared their experiences with MagicaVoxel for creating simple 3D assets. The Hyperfy team clarified that their platform works with any blockchain or without one, with a Solana plugin in development. They also confirmed that team token allocations are vested over 3 years, addressing concerns about token sales. The upcoming V2 release was mentioned as being self-hostable and open source, though still in development with some features like audio integration not yet implemented.\n\n## 2. FAQ\nQ: Can I use this technology with any chain or only with a specific chain? (asked by Revolution) A: Any chain or no chain. By default it has none, but we have a Solana plugin coming. (answered by Ashxn)\nQ: Is Hyperfy open source? (asked by Revolution) A: Self hostable now with platforms coming: https://github.com/hyperfy-xyz/hyperfy (answered by Ashxn)\nQ: Can I make a pvp game or pve game with Hyperfy? (asked by Revolution) A: Yes. (answered by peezy)\nQ: How will v2 compare in performance to games made for desktop? (asked by PurpleSack) A: Unanswered\nQ: Is there any tutorial how to setup V2 to a domain? (asked by J10) A: If you're a dev you can do it right now: https://github.com/hyperfy-xyz/hyperfy/wiki/Deploy-a-world-(Digital-Ocean). If you're not a dev, we'll make this available to everyone soon, no dates set in stone yet. (answered by Ashxn)\nQ: Why did the dev sell all tokens? (asked by Lucas) A: All of our team allocation for the token is vested over 3 years, none of the team has realised or sold any of it. (answered by Ashxn)\nQ: What type of stream should they use if they want to sync audio between instances? (asked by Saori) A: m3u8 stuff or mp4. (answered by 𝚟𝚘𝚡𝚟𝚒𝚎𝚗𝚗𝚎)\n\n## 3. Help Interactions\nHelper: Ashxn | Helpee: devilsadvocate.sol | Context: Asking about avatar options and if CloneX models work in Hyperfy | Resolution: Explained that Hyperfy supports VRM avatars and shared information about the \"hyperbot\" avatar.\nHelper: felixdigit:// | Helpee: devilsadvocate.sol | Context: Looking for CloneX model conversion resources | Resolution: Shared a YouTube tutorial link and a hackmd guide by Metamike for CloneX Virtual World Files.\nHelper: 𝚟𝚘𝚡𝚟𝚒𝚎𝚗𝚗𝚎 | Helpee: Saori | Context: Needed streaming solution for concert audio synchronization | Resolution: Recommended m3u8/mp4 streaming and offered to help set up a concert venue in v1.\nHelper: MJMoonbow aka Tinman | Helpee: bitpixi | Context: Reducing triangle count in AI-generated 3D models | Resolution: Suggested using TripoSR with flag \"--mc-resolution 144-192\" to hit around 30k triangles.\nHelper: maximus | Helpee: uuilliam.k | Context: Returning user asking about world updates | Resolution: Explained that v1 worlds remain untouched while v2 is being developed as open source with performance improvements.\n\n## 4. Action Items\nType: Technical | Description: Implement audio integration for AI agents in virtual worlds | Mentioned By: Morph\nType: Technical | Description: Create a Zerebro avatar for upcoming concert event | Mentioned By: Saori\nType: Technical | Description: Develop audio-reactive lighting for v2 | Mentioned By: Saori\nType: Feature | Description: Integrate text-to-3D model generation via Meshy.ai API | Mentioned By: Saori\nType: Feature | Description: Add voice capabilities to AI agents using OpenAI's voice module | Mentioned By: Morph\nType: Feature | Description: Create a virtual stock exchange | Mentioned By: zobo\nType: Documentation | Description: Create tutorial for setting up v2 on a custom domain for non-developers | Mentioned By: J10\nType: Documentation | Description: Document how to optimize 3D models for browser performance | Mentioned By: bitpixi\nType: Technical | Description: Implement competitive games to showcase platform capabilities | Mentioned By: Ashxn\nType: Feature | Description: Partner with Zerebro team to host a concert in Hyperfy | Mentioned By: MUDBONE",
      "messageCount": 444,
      "userCount": 53
    },
    {
      "channelId": "1326789867312775290",
      "channelName": "🪙│hyper",
      "summary": "# Hyperfy Discord Analysis\n\n## 1. Summary\nThe chat primarily revolves around Hyperfy token price movements, market sentiment, and technical capabilities of the platform. Community members discuss price fluctuations between $0.045-0.06, with many expressing optimism about Hyperfy's long-term value compared to competitors like Decentraland. A significant technical discussion emerged around Hyperfy's positioning as an open-source 3D web engine rather than a traditional metaverse platform. The team clarified they're working on a new avatar model and fixing market cap display issues. Several members compared Hyperfy's technical capabilities to other platforms, highlighting its advantages in being engine-agnostic, open-source, and developer-friendly. The community also discussed the integration of Eliza framework and the potential for creating custom worlds and experiences. There was notable discussion about the platform's technical architecture enabling permissionless integration with various frameworks and its positioning as \"a testing ground for the future of technology.\"\n\n## 2. FAQ\nQ: What tokenomics does HyperFi have? For example, how do you use HyperFi tokens? (asked by Taqman2) A: They will have utility, including through the DAO, worlds, games, etc. The specifics are still being worked out and we wanna make sure it's right. (answered by Ashxn)\nQ: What's the best way to bridge from eth to sol? (asked by Xeta) A: Debridge but i use coinbase. if u go to jup there's a bridge tab i think. (answered by Saori)\nQ: Is the IP thing something specific to these collections? (asked by devilsadvocate.sol) A: All DCL wearables have fair use attached, as long as you aren't repurposing and profiting by reselling. (answered by Morph)\nQ: What do y'all use for alerts? Dex screener kinda sucks for that (asked by devilsadvocate.sol) A: Unanswered\nQ: Do we like this take? 'First virtual sandbox' 'testing ground for anything'? (asked by zobo) A: Unanswered\n\n## 3. Help Interactions\nHelper: Saori | Helpee: Xeta | Context: Asking about the best way to bridge from ETH to SOL | Resolution: Saori suggested using Debridge or Coinbase, and mentioned Jupiter has a bridge tab\nHelper: Morph | Helpee: devilsadvocate.sol | Context: Question about IP rights for DCL wearables | Resolution: Explained that all DCL wearables have fair use attached as long as they aren't repurposed for profit\nHelper: HPrivakos | Helpee: untitled, xyz | Context: Correcting information about Decentraland in a comparison chart | Resolution: Provided accurate information about Decentraland's funding, open-source status, and technical capabilities\nHelper: devilsadvocate.sol | Helpee: jar0d | Context: Providing price analysis for Hyperfy token | Resolution: Shared technical analysis suggesting .054 as local bottom with potential to sink to .043 if broken\nHelper: Ashxn | Helpee: Community | Context: Updating on fixes to platform | Resolution: Confirmed Jupiter logo was fixed and market cap display was being corrected\n\n## 4. Action Items\nType: Technical | Description: Fix market cap display on DEXs to show circulating supply rather than FDV | Mentioned By: sayinshallah\nType: Technical | Description: Create a new Hyperfy avatar model (dark mode version of current one) | Mentioned By: Saori\nType: Feature | Description: Consider integration with Lovense API for VR experiences | Mentioned By: Saori\nType: Feature | Description: Implement token utility through DAO, worlds, and games | Mentioned By: Ashxn\nType: Documentation | Description: Improve discoverability of platform features to avoid confusion | Mentioned By: untitled, xyz\nType: Technical | Description: Tag ai16z dao when sharing posts about Eliza framework integration to attract builders | Mentioned By: Beats\nType: Feature | Description: Explore multiplayer infinite backrooms with environment recognition and custom behavior | Mentioned By: Saori\nType: Feature | Description: Consider open source engine for custom games and modpacks | Mentioned By: peezy\nType: Technical | Description: Implement chain interconnection with every dapp ability to load | Mentioned By: MUDBONE",
      "messageCount": 551,
      "userCount": 43
    },
    {
      "channelId": "1031058655581323324",
      "channelName": "🧊│3d-design",
      "summary": "# Analysis of 🧊│3d-design Discord Channel\n\n## 1. Summary\nThe discussion primarily focused on 3D model optimization for Hyperfy's V2 engine, particularly around collision systems. Ashxn explained that GPU instancing is automatically applied to duplicated GLB models in V2, resulting in excellent performance with a single draw call. HiroP shared detailed information about collider types (Static, Kinematic, Dynamic) and their computational complexity, noting that simpler collision shapes are more efficient. Ashxn confirmed this approach and added that convex colliders are more performant than trimesh colliders, with the limitation that dynamic trimesh colliders don't interact with each other. HiroP developed and shared a Blender script that creates simplified collision meshes from complex models. The community also discussed optimization techniques like LODs configured in Blender, frustum culling, and the impressive bloom effects in V2. Voxvienne suggested adding basic world-editing tools for non-coders to improve environment creation, including skybox/HDRI swapping and coordinate system improvements. Maximus updated an optimization document with the collider information and created a flowchart to help users select appropriate collider types.\n\n## 2. FAQ\nQ: How does GPU instancing work in V2? (implied from discussion) A: If you drop a GLB into a V2 world, it's automatically GPU instanced. Duplicating objects a thousand times results in extremely good performance with one draw call. In Blender, using linked duplicates (cmd+D) also optimizes to one shared draw call. (answered by Ashxn)\nQ: What collider type should I use for different objects? (implied from discussion) A: Use Static for basic objects like buildings and trees; Kinematic for objects controlled through code; Dynamic for physically reactive objects. The computational complexity increases in this order: Nothing -> Static -> Kinematic -> Dynamic. (answered by HiroP)\nQ: Are convex or trimesh colliders better for performance? (implied from discussion) A: Convex colliders are more performant than trimesh. Additionally, two dynamic trimesh colliders don't collide with each other. (answered by Ashxn)\nQ: Have you ever seen the collision editing in Unreal Engine? (asked by hiroP) A: Scoe indicated he would look it up on YouTube. (answered by scoe)\n\n## 3. Help Interactions\nHelper: hiroP | Helpee: Community | Context: Explaining collider types and optimization | Resolution: Provided detailed explanation of Static, Kinematic, and Dynamic colliders with usage guidelines\nHelper: hiroP | Helpee: Community | Context: Creating simplified collision meshes | Resolution: Developed and shared a Blender script (hiros-tools) that creates simplified collision meshes from complex models\nHelper: Ashxn | Helpee: Community | Context: GPU instancing in V2 | Resolution: Explained how duplicated objects are automatically optimized to single draw calls\nHelper: maximus | Helpee: Community | Context: Documenting optimization techniques | Resolution: Created and updated an optimization document with collider information and a decision flowchart\nHelper: Ashxn | Helpee: hiroP | Context: Improving collision mesh generation | Resolution: Suggested using merge by distance to fix disconnected triangles in generated collision meshes\n\n## 4. Action Items\nType: Technical | Description: Implement environment app for modifying HDRI, skybox, fog, sun settings | Mentioned By: Ashxn\nType: Technical | Description: Add transform widget option (activated with Tab key) for precise object positioning | Mentioned By: Ashxn\nType: Technical | Description: Develop Blender addon for building ultra-simplified colliders with one-click attribute setting | Mentioned By: voxvienne\nType: Documentation | Description: Add collider optimization information to optimization documentation | Mentioned By: hiroP\nType: Documentation | Description: Update collider decision flowchart to clarify movement via code vs. physics | Mentioned By: hiroP\nType: Feature | Description: Add ability to swap skybox/HDRI for non-coders | Mentioned By: voxvienne\nType: Feature | Description: Add option to remove grass layer in environments | Mentioned By: voxvienne\nType: Feature | Description: Add sunlight adjustment controls | Mentioned By: voxvienne\nType: Feature | Description: Implement world coordinate system with LOC/ROT/SCALE interface | Mentioned By: voxvienne",
      "messageCount": 89,
      "userCount": 14
    }
  ]
}