{
  "server": "Hyperfy",
  "title": "Hyperfy Discord - 2025-05-02",
  "date": 1746144000,
  "stats": {
    "totalMessages": 124,
    "totalUsers": 27
  },
  "categories": [
    {
      "channelId": "994775534733115412",
      "channelName": "üíª‚îÇdevelopers",
      "summary": "# Discord Chat Analysis for üíª‚îÇdevelopers\n\n## 1. Summary\nThe discussion primarily revolves around Hyperfy v2 development and features. Key technical highlights include:\n\n- Peezy announced the release of the \"ai\" hypkg package (https://hypkg.sh/hypkg/ai/) with a corresponding GitHub branch for Docker users.\n- Ashxn shared updates about PhysX builds, mentioning the creation of a single build that works for both Node and browser environments, which is relevant for logical clients. They also removed PhysX built-in vehicle imports, reducing code size by approximately 4MB.\n- VR functionality was discussed, particularly the current lack of rotation capability in immersive view. Ashxn clarified that body turn and interact buttons still need to be added, noting that snap turn functionality (previously available in v1) is not currently a priority.\n- Gert-Jan Akerboom inquired about implementing an emission intensity slider for a neon letters app, and Ashxn provided guidance on using the emissiveIntensity property with mesh materials.\n- HiroP expressed interest in implementing snap turn functionality for VR and asked for reference implementations.\n- Vox inquired about customizable loading screens for Hyperfy.\n- There was brief mention of vehicle implementations, with Ashxn noting they have better car implementations than PhysX vehicle controllers.\n\n## 2. FAQ\nQ: How can I implement an emission intensity slider for my neon letters app? (asked by Gert-Jan Akerboom) A: Use a range field and connect it to the material with `mesh.material.emissiveIntensity = value`. Make sure your emissive color in Blender isn't black. (answered by Ashxn)\nQ: Is the inability to rotate the view in VR a known issue? (asked by hiroP) A: Current build has no rotation functionality; it will be added later. (answered by vox)\nQ: What does it take to have customizable loading screens for Hyperfy? (asked by vox) A: Unanswered\nQ: How do I implement snap turn in VR? (asked by hiroP) A: It's a common VR feature that applies an offset to rotation by X degrees. (answered by Ashxn)\nQ: Does removing PhysX vehicle imports mean cars are dead? (asked by peezy) A: No, they have better car implementations than PhysX vehicle controllers can provide. (answered by Ashxn)\n\n## 3. Help Interactions\nHelper: Ashxn | Helpee: Gert-Jan Akerboom | Context: Implementing emission intensity slider for neon letters app | Resolution: Explained how to use mesh.material.emissiveIntensity and connect it to a range field, noting the importance of non-black emissive color in Blender\nHelper: vox | Helpee: hiroP | Context: VR rotation functionality in Hyperfy v2 | Resolution: Clarified that rotation is not implemented in the current build and will be added later\nHelper: Ashxn | Helpee: hiroP | Context: Implementing snap turn in VR | Resolution: Explained that snap turn is a common VR feature that applies rotation offset by X degrees\n\n## 4. Action Items\nTechnical: Implement VR rotation/snap turn functionality | Description: Add body turn and interact buttons to VR mode | Mentioned By: Ashxn\nTechnical: Create GitHub actions to build Docker images for modded branches | Description: Automate image creation from modified branches | Mentioned By: peezy\nTechnical: Implement customizable loading screens | Description: Allow for custom loading screens similar to third-person-rig example | Mentioned By: vox\nDocumentation: Document PhysX vehicle alternatives | Description: Explain the raycast vehicle implementation that replaces PhysX vehicle controllers | Mentioned By: Ashxn\nFeature: Create demo videos for AI hypkg | Description: Showcase the functionality of the new AI package | Mentioned By: peezy",
      "messageCount": 63,
      "userCount": 10
    },
    {
      "channelId": "958209074045026327",
      "channelName": "‚ö°‚îÇgeneral",
      "summary": "# Analysis of Discord Chat in \"‚ö°‚îÇgeneral\" Channel\n\n## 1. Summary:\nThe chat primarily revolves around AI integration with Hyperfy, specifically a project called \"Elizafy\" developed by Shaw. This appears to be a headless client that allows AI agents to connect to Hyperfy worlds just like human users would. A demonstration video shows an autonomous agent connecting to a world and navigating independently, with visible key inputs. There was also a significant discussion about Hyperfy v2's GPL license implications for corporate clients, with clarification that the license only applies to core improvements, not applications built on top of the platform. Users expressed excitement about the potential for AI agents as players in virtual worlds and the possibilities for AI-curated environments.\n\n## 2. FAQ:\nQ: Is shaw using the hyperfy engine? (asked by simk) A: Yes, he made a headless client that allows AI agents (Elizafy) to connect to Hyperfy worlds like humans would (answered by Ashxn)\nQ: What is elizafy? (asked by simk) A: A system that allows AI agents to connect to any Hyperfy world just like a human would (answered by Ashxn)\nQ: How would we give the AI \"Vision\" so it can see what is in the world and interact with things? (asked by Agent12) A: Unanswered\n\n## 3. Help Interactions:\nHelper: Ashxn | Helpee: hiroP | Context: Concerns about GPL license implications for using Hyperfy v2 with corporate clients | Resolution: Clarified that the license only applies to core improvements, not applications built on top, comparing it to Linux's GPL license\nHelper: Ashxn | Helpee: simk | Context: Questions about what Elizafy is and if Shaw is using Hyperfy engine | Resolution: Explained that Shaw created a headless client allowing AI agents to connect to Hyperfy worlds like humans\n\n## 4. Action Items:\nTechnical: Implement position/engagement analytics to track user coordinates | Mentioned By: maximus\nFeature: AI vision capabilities for agents to see and interact with world objects | Mentioned By: Agent12\nFeature: Support for autonomous AI agents as players in virtual worlds | Mentioned By: peezy\nFeature: AI-curated worlds | Mentioned By: Agent12",
      "messageCount": 46,
      "userCount": 16
    },
    {
      "channelId": "1326789867312775290",
      "channelName": "ü™ô‚îÇhyper",
      "summary": "# Analysis of Discord Chat in ü™ô‚îÇhyper Channel\n\n## 1. Summary\nThis chat segment contains minimal technical discussion. The conversation primarily consists of users checking the price of HYPER token, with Rick (a bot) responding with price information. One user (Z aka MetaDJ) asks about finding Hyperfy on TradingView, and CheddarQueso responds with a recommendation to use Phantom wallet for trading and Dexscreener for price monitoring, providing what appears to be a token address. The chat shows some sentiment around price movements with comments about selling and \"we back baby\" suggesting a price recovery. There are no substantive technical discussions, problem-solving activities, or implementation details in this segment.\n\n## 2. FAQ\nQ: What pairing do you have on TradingView? I no longer can find Hyperfy. (asked by Z aka MetaDJ) A: I trade in my phantom wallet and watch on Dexscreener 8vBMibwpn8wpfYKbQ9xqzodymg3LjmYec2tSNGRy23K8 (answered by CheddarQueso üßÄ)\n\n## 3. Help Interactions\nHelper: CheddarQueso üßÄ | Helpee: Z aka MetaDJ | Context: User couldn't find Hyperfy on TradingView | Resolution: Suggested using Phantom wallet for trading and Dexscreener for price monitoring, provided a token address\n\n## 4. Action Items\nNo action items identified in this chat segment.",
      "messageCount": 12,
      "userCount": 8
    },
    {
      "channelId": "1031058655581323324",
      "channelName": "üßä‚îÇ3d-design",
      "summary": "The chat segment is extremely brief with only three messages. Ashxn commented on how fog and mountain ranges create a sense of scale in 3D environments. Another user (untitled, xyz) complimented someone's work and inquired about adding depth of field functionality. Finally, ùïΩùñîùñöùñòùñôùñÜùñì asked a brief question about \"hyp\" (likely referring to a feature or update). There were no substantial technical discussions, problem-solving activities, or concrete implementations in this limited exchange.",
      "messageCount": 3,
      "userCount": 3
    }
  ]
}