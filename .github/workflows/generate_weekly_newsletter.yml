# .github/workflows/generate_weekly_newsletter.yml\nname: Generate Weekly Newsletter\n\non:\n  schedule:\n    # Runs every Monday at 6:00 UTC (adjust as needed)\n    - cron: \'0 6 * * 1\'\n  workflow_dispatch: # Allows manual triggering\n\npermissions:\n  contents: write # Needed to write back MD file if storing in repo before upload\n\njobs:\n  generate-newsletter:\n    runs-on: ubuntu-latest\n    env:\n      OPENROUTER_API_KEY: ${{ secrets.OPENROUTER_API_KEY }} # Use repo secret\n      HACKMD_API_TOKEN: ${{ secrets.HACKMD_API_TOKEN }}   # Use repo secret\n\n    steps:\n      - name: Checkout repository\n        uses: actions/checkout@v4\n        with:\n          # Fetch full history to potentially access past daily files if needed for aggregation\n          fetch-depth: 0\n\n      - name: Set up Python\n        uses: actions/setup-python@v5\n        with:\n          python-version: \'3.x\'\n\n      - name: Install dependencies\n        run: |\n          python -m pip install --upgrade pip\n          python -m pip install requests python-dotenv # For hackmd.py and potential LLM call script\n\n      - name: Determine Week Range and Filename\n        id: week_info\n        run: |\n          # Get previous week\'s start (Monday) and end (Sunday) dates\n          # Using GNU date syntax; adjust if using BSD date (macOS)\n          if date --version >/dev/null 2>&1; then\n             # GNU date\n             PREV_WEEK_START=$(date -d \"last monday - 7 days\" +%Y-%m-%d)\n             PREV_WEEK_END=$(date -d \"last sunday\" +%Y-%m-%d)\n             ISO_WEEK=$(date -d \"last sunday\" +%Y-%W) # YYYY-WW using Sunday\'s week number\n          else\n             # Assume BSD date (macOS) - less robust week calculation\n             echo \"Warning: Using BSD date, week calculation might differ slightly.\"\n             PREV_WEEK_START=$(date -v-mon -v-7d +%Y-%m-%d)\n             PREV_WEEK_END=$(date -v-sun +%Y-%m-%d)\n             ISO_WEEK=$(date -v-sun +%Y-%U) # YYYY-WeekNum (Sunday based)\n          fi\n          echo \"week_start=$PREV_WEEK_START\" >> $GITHUB_OUTPUT\n          echo \"week_end=$PREV_WEEK_END\" >> $GITHUB_OUTPUT\n          echo \"output_filename=hackmd/newsletter/${ISO_WEEK}.md\" >> $GITHUB_OUTPUT\n        shell: bash\n\n      - name: Aggregate Weekly Data (Placeholder/Example)\n        id: aggregate_data\n        run: |\n          # --- This is a placeholder - Actual data aggregation needed ---\n          # Option 1: Run a modified script\n          # ./scripts/generate_context_map.sh --start ${{ steps.week_info.outputs.week_start }} --end ${{ steps.week_info.outputs.week_end }} --output /tmp/weekly_data.json\n          # Option 2: Find daily files and combine\n          echo \"Aggregating data from ${{ steps.week_info.outputs.week_start }} to ${{ steps.week_info.outputs.week_end }}\"\n          # Example: find the-council/YYYY-MM-DD.json files in range and jq them together\n          find the-council/ -name \'*.json\' -newermt \"${{ steps.week_info.outputs.week_start }}\" ! -newermt \"$(date -d \'${{ steps.week_info.outputs.week_end }} + 1 day\' +%Y-%m-%d)\" -print0 | \\\n            xargs -0 jq -s \'add | { weekly_data: . }\' > /tmp/weekly_data.json || echo \'{\"weekly_data\": \"No data found for week\"}\' > /tmp/weekly_data.json\n          # --- End Placeholder ---\n\n          if [[ -f \"/tmp/weekly_data.json\" ]]; then\n             echo \"Aggregated data saved to /tmp/weekly_data.json\"\n             # Extract content for the prompt (adapt based on actual aggregated structure)\n             # This example assumes a simple text extraction similar to council script\n             jq -c \'.\' /tmp/weekly_data.json > /tmp/weekly_content.txt # Simplified for example\n             echo \"content_file=/tmp/weekly_content.txt\" >> $GITHUB_OUTPUT\n          else\n             echo \"::error::Failed to aggregate weekly data.\"\n             exit 1\n          fi\n        shell: bash\n\n      - name: Generate Newsletter Content via LLM\n        id: generate_newsletter\n        run: |\n          WEEK_START=\"${{ steps.week_info.outputs.week_start }}\"\n          WEEK_END=\"${{ steps.week_info.outputs.week_end }}\"\n          CONTENT_FILE=\"${{ steps.aggregate_data.outputs.content_file }}\"\n          PROMPT_FILE=\"scripts/prompts/weekly_newsletter.txt\"\n          OUTPUT_MD_FILE=\"${{ steps.week_info.outputs.output_filename }}\"\n\n          # Read the prompt template\n          if [[ ! -f \"$PROMPT_FILE\" ]]; then\n             echo \"::error::Prompt template file not found: $PROMPT_FILE\"\n             exit 1\n          fi\n          PROMPT_TEMPLATE=$(cat \"$PROMPT_FILE\")\n\n          # Read the aggregated content\n          if [[ ! -f \"$CONTENT_FILE\" ]]; then\n             echo \"::error::Aggregated content file not found: $CONTENT_FILE\"\n             exit 1\n          fi\n          AGGREGATED_CONTENT=$(cat \"$CONTENT_FILE\")\n\n          # Replace placeholders in the prompt\n          PROMPT=$(echo \"$PROMPT_TEMPLATE\" | sed \"s/\\[WEEK_START\\]/$WEEK_START/g\" | sed \"s/\\[WEEK_END\\]/$WEEK_END/g\")\n          # Append aggregated content (adjust based on prompt structure)\n          FINAL_PROMPT=\"$PROMPT\\n\\n**Aggregated Weekly Data:**\\n\\\`\\\`\\\`\\n$AGGREGATED_CONTENT\\n\\\`\\\`\\\`\"\n\n          # Prepare payload for OpenRouter API (similar to generate_council_context.py)\n          # Using Claude Sonnet 3.5 as a default, adjust model if needed\n          JSON_PAYLOAD=$(jq -n --arg model \"anthropic/claude-3.5-sonnet\" --arg prompt \"$FINAL_PROMPT\" \\\n            \'{model: $model, messages: [{\"role\": \"user\", \"content\": $prompt}]}')\n\n          echo \"Sending request to OpenRouter for newsletter generation...\"\n          RESPONSE=$(curl -s -X POST \"https://openrouter.ai/api/v1/chat/completions\" \\\n            -H \"Authorization: Bearer $OPENROUTER_API_KEY\" \\\n            -H \"Content-Type: application/json\" \\\n            -H \"HTTP-Referer: https://github.com/elizaOS/knowledge\" \\\n            -H \"X-Title: Weekly Newsletter Generator\" \\\n            -d \"$JSON_PAYLOAD\")\n\n          NEWSLETTER_CONTENT=$(echo \"$RESPONSE\" | jq -r \'.choices[0].message.content // empty\')\n\n          if [[ -z \"$NEWSLETTER_CONTENT\" ]]; then\n            echo \"::error::Failed to generate newsletter content from LLM.\"\n            echo \"Response: $RESPONSE\"\n            exit 1\n          fi\n\n          # Ensure output directory exists\n          mkdir -p \"$(dirname \"$OUTPUT_MD_FILE\")\"\n          # Save the generated content\n          echo \"$NEWSLETTER_CONTENT\" > \"$OUTPUT_MD_FILE\"\n          echo \"Newsletter content saved to $OUTPUT_MD_FILE\"\n          echo \"output_file=$OUTPUT_MD_FILE\" >> $GITHUB_OUTPUT\n        shell: bash\n\n      - name: Upload Newsletter to HackMD\n        if: steps.generate_newsletter.outputs.output_file != \'\'\n        run: |\n          UPLOAD_FILE=\"${{ steps.generate_newsletter.outputs.output_file }}\"\n          CONTENT_TYPE=\"newsletter\" # Assuming hackmd.py maps this to \'dao\' book\n\n          echo \"Uploading $UPLOAD_FILE to HackMD with type $CONTENT_TYPE...\"\n          python3 scripts/hackmd.py upload --file \"$UPLOAD_FILE\" --type \"$CONTENT_TYPE\"\n          # Script handles its own logging/error exit\n        shell: bash\n\n      # Optional: Commit the generated MD file back to the repo\n      # - name: Commit Newsletter Markdown\n      #   if: steps.generate_newsletter.outputs.output_file != \'\'\n      #   run: |\n      #     git config --global user.name \'GitHub Actions Bot\'\n      #     git config --global user.email \'actions@github.com\'\n      #     git add \"${{ steps.generate_newsletter.outputs.output_file }}\"\n      #     # Check if there are changes to commit\n      #     if git diff --staged --quiet; then\n      #       echo \"No changes to commit.\"\n      #     else\n      #       git commit -m \"Automated: Generate weekly newsletter ${{ steps.week_info.outputs.iso_week }}\"\n      #       git push\n      #     fi\n      #   shell: bash\n 