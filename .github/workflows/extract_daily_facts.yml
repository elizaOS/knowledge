name: Extract Daily Facts

on:
  schedule:
    # Runs daily at 1:35 AM UTC (after knowledge sync and aggregation)
    - cron: '35 1 * * *'
  workflow_dispatch: # Allows manual triggering

concurrency:
  group: knowledge-repo-writes
  cancel-in-progress: false

jobs:
  extract-facts:
    runs-on: ubuntu-latest
    permissions:
      contents: write # Need permission to write back to the repo

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Pull latest changes
        run: git pull --rebase origin main || true

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests

      - name: Set execute permission for scripts
        run: |
          chmod +x scripts/extract-facts.py
          chmod +x scripts/aggregate-sources.py

      - name: Aggregate Sources for Today
        id: aggregate_step
        run: |
          ./scripts/aggregate-sources.py # Defaults to today
          echo "aggregated_json_file=the-council/aggregated/$(date +%Y-%m-%d).json" >> $GITHUB_OUTPUT

      - name: Generate Fact Briefing from Aggregated Data
        id: fact_gen_step
        env:
          OPENROUTER_API_KEY: ${{ secrets.OPENROUTER_API_KEY }}
          # COUNCIL_MONTHLY_GOAL: ${{ vars.COUNCIL_MONTHLY_GOAL_VAR || 'Default Goal' }} # Example if needed
        run: |
          INPUT_FILE="${{ steps.aggregate_step.outputs.aggregated_json_file }}"
          OUTPUT_JSON_DIR="the-council/facts"
          OUTPUT_MARKDOWN_DIR="hackmd/facts"
          
          # Ensure output directories exist
          mkdir -p "$OUTPUT_JSON_DIR"
          mkdir -p "$OUTPUT_MARKDOWN_DIR"

          if [ -f "$INPUT_FILE" ]; then
            # Use extract-facts.py with explicit input/output parameters
            OUTPUT_JSON_FILE="$OUTPUT_JSON_DIR/$(date +%Y-%m-%d).json"
            OUTPUT_MARKDOWN_FILE="$OUTPUT_MARKDOWN_DIR/$(date +%Y-%m-%d).md"
            
            ./scripts/extract-facts.py -i "$INPUT_FILE" -o "$OUTPUT_JSON_FILE" -md "$OUTPUT_MARKDOWN_FILE"
            
            echo "fact_json_file=$OUTPUT_JSON_FILE" >> $GITHUB_OUTPUT
            echo "fact_markdown_file=$OUTPUT_MARKDOWN_FILE" >> $GITHUB_OUTPUT
          else
            echo "Input file $INPUT_FILE not found, skipping fact briefing generation."
            exit 1
          fi
      - name: Create permalink for JSON fact file
        run: |
          DAILY_FACT_JSON="the-council/facts/$(date +%Y-%m-%d).json"
          PERMALINK_FACT_JSON="the-council/facts/daily.json"
          if [ -f "$DAILY_FACT_JSON" ]; then
            cp "$DAILY_FACT_JSON" "$PERMALINK_FACT_JSON"
          fi

      - name: Generate RSS feed
        run: |
          python scripts/generate-rss.py

      - name: Commit updated files
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "Automated: Update daily fact briefing for $(date +%Y-%m-%d)"
          file_pattern: "the-council/facts/*.json hackmd/facts/*.md rss/*.xml"
          commit_user_name: "github-actions[bot]"
          commit_user_email: "github-actions[bot]@users.noreply.github.com"
          commit_author: "github-actions[bot] <github-actions[bot]@users.noreply.github.com>"

      - name: Alert on failure
        if: failure()
        run: |
          curl -X POST "${{ secrets.ALERT_WEBHOOK_URL }}" \
            -H "Content-Type: application/json" \
            -d '{
              "content": "<@213767993153290250> ⚠️ **Extract Daily Facts** failed: https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}"
            }'