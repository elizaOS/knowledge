name: Generate Content Posters

on:
  schedule:
    # Runs daily at 10:00 UTC (after HackMD at 9:30, with fresh synced data)
    - cron: '0 10 * * *'
  workflow_dispatch: # Allows manual triggering

concurrency:
  group: knowledge-repo-writes
  cancel-in-progress: false

jobs:
  generate-posters:
    runs-on: ubuntu-latest
    permissions:
      contents: write # To commit posters back to the repo

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Python environment
        uses: ./.github/actions/setup-python-env
        with:
          python-version: '3.12'
          packages: 'requests pillow'

      - name: Get today's date
        id: date
        run: echo "date=$(date +%Y-%m-%d)" >> "$GITHUB_OUTPUT"

      - name: Check for facts file
        id: check-facts
        run: |
          FACTS_FILE="the-council/facts/${{ steps.date.outputs.date }}.json"
          if [ -f "$FACTS_FILE" ]; then
            echo "facts_exist=true" >> "$GITHUB_OUTPUT"
            echo "facts_file=$FACTS_FILE" >> "$GITHUB_OUTPUT"
          else
            # Fallback to daily.json symlink
            if [ -f "the-council/facts/daily.json" ]; then
              echo "facts_exist=true" >> "$GITHUB_OUTPUT"
              echo "facts_file=the-council/facts/daily.json" >> "$GITHUB_OUTPUT"
            else
              echo "facts_exist=false" >> "$GITHUB_OUTPUT"
              echo "No facts file found for today"
            fi
          fi

      - name: Generate Illustrations
        if: steps.check-facts.outputs.facts_exist == 'true'
        id: generate
        env:
          OPENROUTER_API_KEY: ${{ secrets.OPENROUTER_API_KEY }}
        run: |
          cd scripts/posters
          python illustrate.py --batch -f "../../${{ steps.check-facts.outputs.facts_file }}" --with-icons || echo "Generation had errors"
        continue-on-error: true

      - name: Upload to CDN (optional)
        if: steps.check-facts.outputs.facts_exist == 'true'
        env:
          BUNNY_STORAGE_ZONE: ${{ secrets.BUNNY_STORAGE_ZONE }}
          BUNNY_STORAGE_PASSWORD: ${{ secrets.BUNNY_STORAGE_PASSWORD }}
          BUNNY_CDN_URL: ${{ secrets.BUNNY_CDN_URL }}
        run: |
          if [ -n "$BUNNY_STORAGE_PASSWORD" ] && [ -d "media/${{ steps.date.outputs.date }}" ]; then
            python scripts/integrations/cdn/upload.py "media/${{ steps.date.outputs.date }}/" --update-manifest || true
          else
            echo "Skipping CDN upload (no credentials or no media generated)"
          fi
        continue-on-error: true

      - name: Enrich source files with posters
        if: steps.check-facts.outputs.facts_exist == 'true'
        run: |
          # Get briefing_date from facts file (posters use this date)
          BRIEFING_DATE=$(python3 -c "import json; print(json.load(open('${{ steps.check-facts.outputs.facts_file }}')).get('briefing_date', '${{ steps.date.outputs.date }}'))")
          echo "Briefing date: $BRIEFING_DATE"

          # Enrich json source file if it exists (skip existing upstream URLs)
          # Note: json/ already contains CDN URLs (json-cdn/ is deprecated)
          if [ -f "ai-news/elizaos/json/${BRIEFING_DATE}.json" ]; then
            python scripts/etl/enrich-facts-media.py --source \
              -f "ai-news/elizaos/json/${BRIEFING_DATE}.json" \
              -m "media/daily/${BRIEFING_DATE}/manifest.json" \
              --cdn-base "https://cdn.elizaos.news/media/daily/${BRIEFING_DATE}" \
              --skip-existing \
              -v || echo "Source enrichment skipped"
          else
            echo "No json file found for ${BRIEFING_DATE}"
          fi
        continue-on-error: true

      - name: Enrich facts with media URLs
        if: steps.check-facts.outputs.facts_exist == 'true'
        run: |
          python scripts/etl/enrich-facts-media.py \
            -f "${{ steps.check-facts.outputs.facts_file }}" \
            -a "the-council/aggregated/${{ steps.date.outputs.date }}.json" \
            -m "media/${{ steps.date.outputs.date }}/manifest.json" \
            --cdn-base "https://cdn.elizaos.news/posters/${{ steps.date.outputs.date }}" \
            --skip-existing \
            -v || echo "Enrichment skipped (missing files)"
        continue-on-error: true

      - name: Generate RSS feeds
        run: python scripts/etl/generate-rss.py
        continue-on-error: true

      - name: Cleanup old media (keep last 7 days)
        run: |
          # Find and remove media directories older than 7 days
          # Media dirs are named YYYY-MM-DD
          CUTOFF_DATE=$(date -d '7 days ago' +%Y-%m-%d)
          echo "Removing media directories older than $CUTOFF_DATE"

          for dir in media/20??-??-??/; do
            if [ -d "$dir" ]; then
              DIR_DATE=$(basename "$dir")
              if [[ "$DIR_DATE" < "$CUTOFF_DATE" ]]; then
                echo "Removing old media: $dir"
                rm -rf "$dir"
              fi
            fi
          done

      - name: Commit and Push
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "Automated: Generate posters for ${{ steps.date.outputs.date }}"
          file_pattern: "media/ the-council/facts/*.json ai-news/elizaos/json/*.json rss/"
          commit_user_name: "github-actions[bot]"
          commit_user_email: "github-actions[bot]@users.noreply.github.com"
          commit_author: "github-actions[bot] <github-actions[bot]@users.noreply.github.com>"