# elizaos/eliza Daily Update (Aug 12, 2025)
## OVERVIEW 
Today's focus was on enhancing scenario testing capabilities with new evaluators for LLM interactions and closing out several key feature implementations related to natural language agent interaction, dynamic plugin loading, and advanced mocking.

## KEY TECHNICAL DEVELOPMENTS

### Build System Updates
- The `checkout` action for the build system was updated to version 5, ensuring the use of the latest and most secure action for repository checkout in workflows. ([#5762](https://github.com/elizaos/eliza/pull/5762))

## NEWLY OPENED PULL REQUESTS
- **Build System Update**: A new pull request, [#5762](https://github.com/elizaos/eliza/pull/5762), was opened to update the `checkout` action to version 5, aiming to improve the stability and security of the build process.

## CLOSED ISSUES

### Enhanced Scenario Testing Capabilities
- The implementation of natural language agent interaction and response validation was completed, enabling scenarios to test agent behavior through natural language rather than direct code execution. ([#5727](https://github.com/elizaos/eliza/issues/5727))
- The plugin specification and dynamic loading feature was successfully implemented, allowing scenarios to declare required plugins and enabling dynamic loading. ([#5725](https://github.com/elizaos/eliza/issues/5725))
- Conditional mocking and complex response structures were implemented, enhancing the mocking system to support conditional responses based on input parameters and complex response structures with metadata. ([#5726](https://github.com/elizaos/eliza/issues/5726))

## NEW ISSUES

### New Scenario Evaluators Proposed
- A new feature request, [#5758](https://github.com/elizaos/eliza/issues/5758), was opened to add a Token Count Evaluator for asserting on input/output/total token counts in LLM calls during scenario steps.
- Another feature request, [#5757](https://github.com/elizaos/eliza/issues/5757), proposes an Execution Time Evaluator to measure per-step execution duration and assert against bounds.
- Issue [#5759](https://github.com/elizaos/eliza/issues/5759) was created to introduce a Cost Evaluator for asserting the estimated dollar cost of LLM usage per step, derived from token counts.
- A Consistency Evaluator was proposed in [#5760](https://github.com/elizaos/eliza/issues/5760) to run the same step multiple times and assert consistency over a chosen metric.
- Finally, [#5761](https://github.com/elizaos/eliza/issues/5761) suggests adding a Step Count Evaluator to assert on the number of agent/tool/action steps taken to complete a scenario step.

## ACTIVE ISSUES
No active issues with more than 3 comments.